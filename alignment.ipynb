{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the first section defines all the functions used in this workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import copy\n",
    "import glob,os\n",
    "import cloudComPy as cc\n",
    "def prepare_dataset(voxel_size):\n",
    "    print(\":: Load two point clouds and disturb initial pose.\")\n",
    "\n",
    "    demo_icp_pcds = o3d.data.DemoICPPointClouds()\n",
    "    source = o3d.io.read_point_cloud(demo_icp_pcds.paths[0])\n",
    "    target = o3d.io.read_point_cloud(demo_icp_pcds.paths[1])\n",
    "    trans_init = np.asarray([[0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0],\n",
    "                             [0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0]])\n",
    "    source.transform(trans_init)\n",
    "    draw_registration_result(source, target, np.identity(4))\n",
    "\n",
    "    source_down, source_fpfh = preprocess_point_cloud(source, voxel_size)\n",
    "    target_down, target_fpfh = preprocess_point_cloud(target, voxel_size)\n",
    "    return source, target, source_down, target_down, source_fpfh, target_fpfh\n",
    "\n",
    "def execute_fast_global_registration(source_down, target_down, source_fpfh,\n",
    "                                     target_fpfh, voxel_size):\n",
    "    distance_threshold = voxel_size * 0.5\n",
    "    print(\":: Apply fast global registration with distance threshold %.3f\" \\\n",
    "            % distance_threshold)\n",
    "    result = o3d.pipelines.registration.registration_fgr_based_on_feature_matching(\n",
    "        source_down, target_down, source_fpfh, target_fpfh,\n",
    "        o3d.pipelines.registration.FastGlobalRegistrationOption(\n",
    "            maximum_correspondence_distance=distance_threshold))\n",
    "    return result\n",
    "def draw_registration_result(source, target, zoom,up,front,lookat):\n",
    "    source_temp = copy.deepcopy(source)\n",
    "    target_temp = copy.deepcopy(target)\n",
    "    source_temp.paint_uniform_color([1, 0.706, 0])\n",
    "    target_temp.paint_uniform_color([0, 0.651, 0.929])\n",
    "    # source_temp.transform(transformation)\n",
    "    o3d.visualization.draw_geometries([source_temp, target_temp],\n",
    "                                      zoom=zoom,\n",
    "                                      up=up,\n",
    "                                      front=front,\n",
    "                                      lookat=lookat\n",
    "                                      )\n",
    "def preprocess_point_cloud(pcd, voxel_size):\n",
    "    print(\":: Downsample with a voxel size %.3f.\" % voxel_size)\n",
    "    pcd_down = pcd.voxel_down_sample(voxel_size)\n",
    "\n",
    "    radius_normal = voxel_size * 2\n",
    "    print(\":: Estimate normal with search radius %.3f.\" % radius_normal)\n",
    "    pcd_down.estimate_normals(\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=radius_normal, max_nn=30))\n",
    "\n",
    "    radius_feature = voxel_size * 5\n",
    "    print(\":: Compute FPFH feature with search radius %.3f.\" % radius_feature)\n",
    "    pcd_fpfh = o3d.pipelines.registration.compute_fpfh_feature(\n",
    "        pcd_down,\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=radius_feature, max_nn=100))\n",
    "    return pcd_down, pcd_fpfh\n",
    "\n",
    "def loadPointCloud_toO3D(fp):\n",
    "    cctemp = cc.loadPointCloud(fp)\n",
    "    xyz = cctemp.toNpArrayCopy()\n",
    "    temp = o3d.geometry.PointCloud()\n",
    "    temp.points = o3d.utility.Vector3dVector(xyz)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section then loads the clouds. note that it is written to look for files in \"folder\" with the \"PCD\" file type in  and don't start with \"aligned...\"\n",
    "\n",
    "the last step is downsampling the base cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded  E_20230727_001.e57\n",
      "loaded  E_20230727_003.e57\n",
      "loaded  E_20230727_005.e57\n",
      "loaded base and downsampled\n"
     ]
    }
   ],
   "source": [
    "folder = r\"X:\\Projects\\LidarScans\\E\\Individual_scans\\E_20230727\"\n",
    "basefilepath = r\"X:\\PersonalShare\\Luke\\code\\rockfall_processing\\example\\aligned_E_20210924.bin\"\n",
    "threshold = 0.1\n",
    "icpv = 0.02\n",
    "\n",
    "cloudpaths = os.listdir(folder)\n",
    "clouds=[]\n",
    "cloud_types = ('.e57','.pcd','.ply','.bin')\n",
    "for cloudpath in cloudpaths:\n",
    "    if cloudpath.endswith(cloud_types) and ('aligned' not in cloudpath):\n",
    "        temp = loadPointCloud_toO3D(os.path.join(folder,cloudpath))\n",
    "        temp = temp.voxel_down_sample(icpv)\n",
    "        clouds.append(temp)\n",
    "        print('loaded ',cloudpath)\n",
    "base = loadPointCloud_toO3D(basefilepath)\n",
    "base = base.voxel_down_sample(icpv)\n",
    "print('loaded base and downsampled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Downsample with a voxel size 0.850.\n",
      ":: Estimate normal with search radius 1.700.\n",
      ":: Compute FPFH feature with search radius 4.250.\n",
      ":: Downsample with a voxel size 0.850.\n",
      ":: Estimate normal with search radius 1.700.\n",
      ":: Compute FPFH feature with search radius 4.250.\n",
      ":: Apply fast global registration with distance threshold 0.425\n",
      ":: Downsample with a voxel size 0.850.\n",
      ":: Estimate normal with search radius 1.700.\n",
      ":: Compute FPFH feature with search radius 4.250.\n",
      ":: Apply fast global registration with distance threshold 0.425\n",
      ":: Downsample with a voxel size 0.850.\n",
      ":: Estimate normal with search radius 1.700.\n",
      ":: Compute FPFH feature with search radius 4.250.\n",
      ":: Apply fast global registration with distance threshold 0.425\n"
     ]
    }
   ],
   "source": [
    "v = 0.85 #should be good for E\n",
    "basedown,basefpfh = preprocess_point_cloud(base,v)\n",
    "transforms = []\n",
    "for i,cloud in enumerate(clouds):\n",
    "    tempdown,tempfpfh = preprocess_point_cloud(cloud,v)\n",
    "    result_fast = execute_fast_global_registration(tempdown, basedown,\n",
    "                                            tempfpfh,basefpfh,\n",
    "                                            v)\n",
    "    tempdown.transform(result_fast.transformation) #tempdown is created just for quick visualization of results. it's transformed here.\n",
    "    \n",
    "    #you can write out the small roughly aligned cloud if you want here (but just as easy to quickly visualize using the code block after this one)\n",
    "    # o3d.io.write_point_cloud(os.path.join(folder,'aligned_rough_'+str(i)+'.ply'),tempdown)\n",
    "\n",
    "\n",
    "    cloud.transform(result_fast.transformation) #then we apply transformation to the full density cloud.\n",
    "    transforms.append(result_fast.transformation)  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if some or all of the rough alignments look good, you can run this to write them to files\n",
    "for i,cloud  in enumerate(clouds):\n",
    "    o3d.io.write_point_cloud(os.path.join(folder,'aligned_rough_full_'+str(i)+'.ply'),cloud)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you can use this to draw the registration result quickly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cloud in clouds:\n",
    "    draw_registration_result(cloud,basedown,\n",
    "                            zoom = 0.02,\n",
    "                            up=[ -0.91284696632868534, 0.38836539258315206, -0.1260267348948248 ],\n",
    "                            front = [ -0.053238637793158662, 0.19281089836405263, 0.97979059238082911 ],\n",
    "                            lookat = [ -9.0112673659519142, 10.457115027765134, 1893.2071603034337 ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ICP**\n",
    "\n",
    "with the roughly aligned clouds you can then run ICP for fine alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load roughly aligned clouds again\n",
    "import numpy as np\n",
    "import cloudComPy as cc\n",
    "\n",
    "basefilepath = r\"X:\\PersonalShare\\Luke\\code\\rockfall_processing\\example\\E_20210924_aligned.bin\" #same as before\n",
    "c1 = r\"X:\\PersonalShare\\Luke\\code\\rockfall_processing\\example\\E_20240328_001_ex.bin\"\n",
    "c2 = r\"X:\\PersonalShare\\Luke\\code\\rockfall_processing\\example\\E_20240328_003_ex.bin\"\n",
    "c3 = r\"X:\\PersonalShare\\Luke\\code\\rockfall_processing\\example\\E_20240328_005_ex.bin\"\n",
    "fps = [c1,c2,c3]\n",
    "ccClouds = []\n",
    "for fp in fps:\n",
    "    c = cc.loadPointCloud(fp)\n",
    "    ccClouds.append(c)\n",
    "\n",
    "basecloud = cc.loadPointCloud(basefilepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converted cloud from O3D to CloudComPy\n",
      "converted cloud from O3D to CloudComPy\n",
      "converted cloud from O3D to CloudComPy\n"
     ]
    }
   ],
   "source": [
    "# OR RUN THIS IF YOU WANT TO KEEP ALL THE SAME POINT CLOUDS AS WERE USED BEFORE IN THE ROUGH ALIGNMENT\n",
    "import cloudComPy as cc\n",
    "ccClouds = []\n",
    "for cloud in clouds:\n",
    "    temp=cc.ccPointCloud()\n",
    "    temp.coordsFromNPArray_copy(np.asarray(cloud.points,dtype=np.float32))\n",
    "    ccClouds.append(temp)\n",
    "    print('converted cloud from O3D to CloudComPy')\n",
    "\n",
    "basecloud=cc.ccPointCloud()\n",
    "basecloud.coordsFromNPArray_copy(np.asarray(base.points,dtype=np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CC_FILE_ERROR.CC_FERR_NO_ERROR\n",
      "CC_FILE_ERROR.CC_FERR_NO_ERROR\n",
      "CC_FILE_ERROR.CC_FERR_NO_ERROR\n"
     ]
    }
   ],
   "source": [
    "#%% ICP ALIGNMENT\n",
    "numICP = 3\n",
    "samplinglimits = [100000,200000,300000]\n",
    "overlapRatios = [0.5,0.3,0.2]\n",
    "for i,cloud in enumerate(ccClouds):\n",
    "    for j in range(numICP):\n",
    "        ICPres = cc.ICP(data=cloud,model=basecloud,minRMSDecrease = 1.e-5,\n",
    "                    maxIterationCount = 20,\n",
    "                    randomSamplingLimit = samplinglimits[j],\n",
    "                    removeFarthestPoints = True,\n",
    "                    method = cc.CONVERGENCE_TYPE.MAX_ERROR_CONVERGENCE,\n",
    "                    finalOverlapRatio = overlapRatios[j], #MAY WANT TO ADJUST THIS BASED ON THE SITE CONDITIONS\n",
    "                    adjustScale = False\n",
    "                    )\n",
    "\n",
    "        cloud.applyRigidTransformation(ICPres.transMat)\n",
    "    res = cc.SavePointCloud(cloud,folder+f'\\cloud_{i}_ICPalign.bin')\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<CC_FILE_ERROR.CC_FERR_NO_ERROR: 0>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RUN THIS TO MERGE THE COMPONENT CLOUDS AND SAVE THE MERGED CLOUD\n",
    "for i,cloud in enumerate(ccClouds):\n",
    "\n",
    "    if i == 0:\n",
    "        mergedCloud = cloud.cloneThis()\n",
    "        \n",
    "    else:\n",
    "        mergedCloud.fuse(cloud)\n",
    "\n",
    "assert mergedCloud.size() == np.sum([x.size() for x in ccClouds])\n",
    "\n",
    "cc.SavePointCloud(mergedCloud,folder+'\\mergedCloud.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0006735707 0.007013787\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<CC_FILE_ERROR.CC_FERR_NO_ERROR: 0>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RUN THIS TO DO A QUICK M3C2 COMPARISON BETWEEN THE NEWLY MERGED CLOUD AND THE BASE\n",
    "if cc.isPluginM3C2():\n",
    "    import cloudComPy.M3C2\n",
    "M3C2params = r'X:\\Projects\\LidarScans\\GW\\Alignments\\m3c2_params_GW_quickcompare.txt'\n",
    "quickcompare = cc.M3C2.computeM3C2([basecloud,mergedCloud],M3C2params)\n",
    "change = quickcompare.getScalarField(2).toNpArray()\n",
    "filt = (change>-0.03) & (change < 0.03)\n",
    "print(np.nanmean(change[filt]),np.nanstd(change[filt]))\n",
    "\n",
    "cc.SavePointCloud(quickcompare,folder+'\\quickcompare.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example, or test results for the quick compare were a mean of 0.0004 and a standard deviation of 0.00718, which is pretty good! Should still do a visual validation to make sure there aren't problem areas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CloudComPy310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
